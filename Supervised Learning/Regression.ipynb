{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605da1a2-c7ae-4634-9def-48d6f48770d1",
   "metadata": {},
   "source": [
    "### Supervised Machine Learning\n",
    "\n",
    "Supervised Machine Learning involves training a model on a labeled dataset. This means the data you use to train the model includes both the input data and the correct output. The goal is for the model to learn to predict the output from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927500a-c20d-4a86-8b05-773c336ff717",
   "metadata": {},
   "source": [
    "#### Types of Problems:\n",
    "\n",
    "**Regression**: Predicting a continuous value (e.g., house prices).\n",
    "\n",
    "**Classification**: Predicting a category (e.g., spam or not spam in email filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365d8bf-e426-40be-940f-35d8d28a2550",
   "metadata": {},
   "source": [
    "#### Common Algorithms:\n",
    "\n",
    "* Linear Regression for regression problems\n",
    "* Logistic Regression for classification problems\n",
    "* Decision Trees\n",
    "* Support Vector Machines (SVM)\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e2a7c-ea14-4350-b9ff-47eb84bd3575",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Linear regression is a fundamental statistical and machine learning technique used to model the relationship between a dependent variable and one or more independent variables. The goal is to find a linear relationship between these variables. Linear regression is a way to understand the relationship between two things by drawing a straight line through data points. It's like finding the best-fitting line through a set of points on a graph. This line helps us predict future values.\n",
    "\n",
    "## Basic Concept\n",
    "\n",
    "1. **Dependent Variable (Target)**: This is what you're trying to predict or explain (e.g., house prices).\n",
    "2. **Independent Variables (Features)**: These are the variables you're using to predict the dependent variable (e.g., size of the house, number of bedrooms).\n",
    "\n",
    "## The Linear Equation\n",
    "\n",
    "Linear regression models this relationship with a linear equation, which in its simplest form (with one independent variable) is:\n",
    "\n",
    "\\[ Y = \\beta_0 + \\beta_1X + \\epsilon \\]\n",
    "\n",
    "- `Y` is the dependent variable.\n",
    "- `X` is the independent variable.\n",
    "- `\\beta_0` is the y-intercept (the value of `Y` when `X = 0`).\n",
    "- `\\beta_1` is the slope of the line (how much `Y` changes for a unit change in `X`).\n",
    "- `\\epsilon` is the error term, accounting for the fact that the relationship isn't perfectly linear.\n",
    "\n",
    "# Simple Linear Regression Equation Explained\r\n",
    "\r\n",
    "Simple Linear Regression is a way to show the relationship between two things using a straight line. It's like finding the best straight path through a series of points on a graph. This line helps us predict how one thing changes when another thing changes.\r\n",
    "\r\n",
    "## Understanding the Equation\r\n",
    "\r\n",
    "The equation for simple linear regression is:\r\n",
    "\r\n",
    "`Y = a + bX`\r\n",
    "\r\n",
    "This might look a bit technical, but it's actually quite straightforward when you break it down:\r\n",
    "\r\n",
    "- `Y`: This is what we want to predict or understand better. For example, it could be the price of a house.\r\n",
    "- `X`: This is what we think affects `Y`. In our house price example, this could be the size of the house.\r\n",
    "- `a`: This is where the line crosses the Y-axis when `X` is zero. It's like the starting point of our line if `X` had no effect.\r\n",
    "- `b`: This shows how much `Y` changes when `X` changes. If `b` is positive, it means that as `X` increases, `Y` also increases. In our example, a larger house size would mean a higher price.\r\n",
    "\r\n",
    "## A Simple Example\r\n",
    "\r\n",
    "Imagine we want to understand how the number of hours spent studying affects a student's test score:\r\n",
    "\r\n",
    "- `Y` (what we want to predict): Test score\r\n",
    "- `X` (what we think affects the score): Hours spent studying\r\n",
    "- `a`: The score a student might get if they didn't study at all\r\n",
    "- `b`: How much the score is expected to increase for each additional hour of study\r\n",
    "\r\n",
    "If our equation is `Y = 10 + 5X`, it means that if a student doesn't study at all (`X=0`), the expected score would be 10 (`Y=10`). For each hour spent studying, the score increases by 5 points.\r\n",
    "\r\n",
    "## Conclusion\r\n",
    "\r\n",
    "The simple linear regression equation is a basic but powerful tool to understand and predict how two things are related. It helps us draw a line through data points on a graph, showing the average effect of one thing on another.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bb794-783e-4c76-986f-0ef3027d5563",
   "metadata": {},
   "source": [
    "## Example: Study Hours and Exam Marksion?\r\n",
    "\r\n",
    "Imagine you're trying to figure out if there's a relationship between the number of hours you study and the marks you get in an exam. In this case, the number of hours studied is what you control (independent variable), and the marks you get is what you want to predict (dependent variam Marks\r\n",
    "\r\n",
    "Let's say we plot the study hours and exam marks of different students on a graph:\r\n",
    "\r\n",
    "- The **horizontal axis (X-axis)** shows the study hours.\r\n",
    "- The **vertical axis (Y-axis)** shows the exam marks.\r\n",
    "\r\n",
    "Each point on this graph represents a student's study hours and their corresponding exam marks.\r\n",
    "\r\n",
    "## Finding the Best-Fitting Line\r\n",
    "\r\n",
    "Linear regression helps us draw a straight line through these points. This line represents the average effect of studying for a certain number of hours on the exam marks. The goal is to draw this line so that it's as close as possible to all the points.\r\n",
    "\r\n",
    "### How Does This Line Help?\r\n",
    "\r\n",
    "1. **Prediction**: If you know how many hours a student plans to study, you can use the line to predict their exam marks.\r\n",
    "2. **Understanding Relationship**: The line also shows the relationship between study hours and marks. If the line goes up as it moves from left to right, it means more study hours generally lead to higher marks.\r\n",
    "\r\n",
    "## Real-World Example\r\n",
    "\r\n",
    "Think about a real estate agent trying to price a house. They might use linear regression to understand the relationship between the house’s size (in square feet) and its selling price. Here, the size of the house is the independent variable, and the selling price is the dependent variable.\r\n",
    "\r\n",
    "## Conclusion\r\n",
    "\r\n",
    "In summary, linear regression is a way to understand how two things are related. It's like drawing the best line through a scatter of dots on a graph to predict and understand how changing one thing (like study hours or house size) might affect another thing (like exam marks or selling price).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe13f0-0ada-42ac-a64e-3cd5aea04261",
   "metadata": {},
   "source": [
    "# Difference Between Correlation and Linear Regression\r\n",
    "\r\n",
    "Understanding data often involves looking at the relationship between variables. Two common methods to do this are correlation and linear regression. While they may seem similar, they serve different purposes and convey different types of information.\r\n",
    "\r\n",
    "## Correlation\r\n",
    "\r\n",
    "Correlation measures the strength and direction of the linear relationship between two variables. It's a statistical technique that tells us how closely variables move together.\r\n",
    "\r\n",
    "### Key Points:\r\n",
    "\r\n",
    "- **Scale**: The correlation coefficient ranges from -1 to 1. A value close to 1 means a strong positive relationship, -1 means a strong negative relationship, and 0 means no linear relationship.\r\n",
    "- **Direction**: Indicates whether the variables increase/decrease together (positive correlation) or move in opposite directions (negative correlation).\r\n",
    "- **No Distinction**: Treats both variables equally; doesn’t distinguish between dependent and independent variables.\r\n",
    "- **Purpose**: Mainly used to quantify the degree of association between variables.\r\n",
    "\r\n",
    "## Linear Regression\r\n",
    "\r\n",
    "Linear regression, on the other hand, is used to predict the value of a dependent variable based on the value of at least one independent variable. It explains the impact of changes in an independent variable on the dependent variable.\r\n",
    "\r\n",
    "### Key Points:\r\n",
    "\r\n",
    "- **Equation**: Uses the equation `Y = a + bX`, where `Y` is the dependent variable, `X` is the independent variable, `a` is the intercept, and `b` is the slope.\r\n",
    "- **Predictive**: Focuses on the relationship and predicts future outcomes.\r\n",
    "- **Causality Direction**: Implies a directional effect (X influences Y).\r\n",
    "- **Purpose**: Used to understand and predict the behavior of one variable based on the behavior of another.\r\n",
    "\r\n",
    "## Comparison\r\n",
    "\r\n",
    "| Aspect         | Correlation         | Linear Regression  |\r\n",
    "| -------------- | ------------------- | ------------------ |\r\n",
    "| Purpose        | Measures the strength and direction of a linear relationship. | Predicts and explains the relationship between variables. |\r\n",
    "| Directionality | Bidirectional; doesn’t imply cause and effect. | Unidirectional; implies a predictive relationship from independent to dependent variable. |\r\n",
    "| Output         | Correlation coefficient (a single number). | Equation that describes the line of best fit. |\r\n",
    "| Application    | Used when simply understanding the relationship is the goal. | Used when the goal is to predict or explain changes in one variable due to another. |\r\n",
    "\r\n",
    "## Conclusion\r\n",
    "\r\n",
    "In summary, while correlation and linear regression may seem similar as they both deal with relationships between variables, they serve different purposes. Correlation quantifies the strength of a relationship, whereas linear regression provides a model to predict and explain changes in variables.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee5641-7cac-487b-a737-321caaa33024",
   "metadata": {},
   "source": [
    "\n",
    "## Assumptions\n",
    "\n",
    "Linear regression relies on several key assumptions:\n",
    "   \n",
    "- **Linearity**: The relationship between the independent and dependent variables should be linear.\n",
    "- **Independence**: Observations should be independent of each other.\n",
    "- **Homoscedasticity**: The residuals (difference between observed and predicted values) should have constant variance.\n",
    "- **Normal Distribution of Errors**: The residuals should be normally distributed.\n",
    "\n",
    "## Multiple Linear Regression\n",
    "\n",
    "When there are multiple independent variables, the equation becomes:\n",
    "\n",
    "\\[ Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n + \\epsilon \\]\n",
    "\n",
    "## Fitting the Model\n",
    "\n",
    "- **Least Squares Method**: This is the most common method used to estimate the coefficients (`\\beta`) of the linear regression model. It minimizes the sum of the squared differences between observed and predicted values.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "- **R-squared**: Measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "- **Adjusted R-squared**: Adjusted for the number of predictors in the model, used for multiple linear regression.\n",
    "- **Residual Analysis**: Assessing the residuals (errors) to check if they meet the assumptions.\n",
    "\n",
    "## Applications\n",
    "\n",
    "Linear regression is used in various fields like economics (predicting GDP), finance (stock prices), biology (drug response), and many more.\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Cannot model non-linear relationships.\n",
    "- Sensitive to outliers.\n",
    "- Assumes a linear relationship between variables and constant variance.\n",
    "\n",
    "In summary, linear regression is a starting point for regression analysis. It's straightforward to understand and implement but has limitations, especially when dealing with non-linear data or outliers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
