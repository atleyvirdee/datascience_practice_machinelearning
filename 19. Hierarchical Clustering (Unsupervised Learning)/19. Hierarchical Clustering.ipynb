{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829e21a3-18d2-49ac-8814-a7b51d2f2d4e",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "\n",
    "## 1. Definition\n",
    "\n",
    "Hierarchical Clustering is an unsupervised learning algorithm that builds a hierarchy of clusters. This algorithm starts by treating each data point as a single cluster. Then, it iteratively executes the following steps: identify the two clusters that are closest together, and merge them into a single cluster. This process is repeated until all points are clustered into a single, all-encompassing cluster. Hierarchical clustering can be visualized using a dendrogram, a tree-like diagram that shows the arrangements of the clusters produced by the algorithm. There are two types of hierarchical clustering: Agglomerative (bottom-up approach) and Divisive (top-down approach).\n",
    "\n",
    "## Explanation in Layman's Terms\n",
    "\n",
    "Imagine you are organizing a large, multi-course dinner and need to decide on the menu. Each dish you consider is like a data point. In hierarchical clustering, you start by considering each dish individually, thinking about how they might pair with others.\n",
    "\n",
    "At first, you group dishes that naturally go together â€“ like pairing soups and salads or meats and gravies. As the menu starts to take shape, these small groups (clusters) are slowly combined into larger ones. For instance, you might merge the soup-salad cluster with a bread cluster to form a starter course. This process continues, gradually building up the courses (larger clusters), until you have a complete menu (one big cluster that encompasses all dishes).\n",
    "\n",
    "Hierarchical clustering works similarly. It starts by considering each data point separately and then gradually combines them into larger and more comprehensive groups. The process is like creating a menu where you start with individual dishes and slowly build up to complete courses, constantly considering which dishes (data points) complement each other best as you go along.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67d639-2d27-4f5f-aa14-c45f18b09379",
   "metadata": {},
   "source": [
    "## 2.History of Hierarchical Clustering \n",
    "\n",
    "1. **Development and History**:\n",
    "\n",
    "- **Origins**: Hierarchical clustering does not have a single inventor; it evolved over time with contributions from various researchers from the early to mid-20th century.\n",
    "- **Purpose**: Developed as a method for statistical data analysis, hierarchical clustering seeks to build a hierarchy of clusters without pre-specifying the number of clusters.\n",
    "\n",
    "2. **Name Origin**:\n",
    "\n",
    "- **Hierarchical**: Indicates the algorithm's approach to constructing a hierarchy or tree of clusters, known as a dendrogram, which allows for a detailed view of the data's cluster structure.\n",
    "- **Clustering**: Describes the objective to group data points into clusters based on their similarity, but unlike K-means, it does not require the number of clusters to be defined in advance.The term \"Hierarchical Clustering\" precisely describes its methodology: creating a hierarchical decomposition of the dataset into clusters, revealing the nested structure of data groupings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbadce8-3acb-48e0-b1ca-0c298c0d96d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
