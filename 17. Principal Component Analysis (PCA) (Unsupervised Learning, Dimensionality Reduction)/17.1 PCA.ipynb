{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82117565-abd2-4aa0-8007-2ef3d21db119",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "## 1. Definition\n",
    "\n",
    "Principal Component Analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This technique is widely used in data preprocessing for machine learning. The number of principal components is less than or equal to the number of original variables. The transformation is defined in such a way that the first principal component has the largest possible variance, and each succeeding component, in turn, has the highest variance possible under the constraint that it is orthogonal to the preceding components.\n",
    "\n",
    "## Explanation in Layman's Terms\n",
    "\n",
    "Imagine you're a chef in a kitchen with a huge number of ingredients (variables) at your disposal. However, your kitchen space (the model) is limited, and you can't use all of them at once. To make an efficient and delicious dish, you need to select the most important ingredients that contribute the most to the taste (variance) of the dish.\n",
    "\n",
    "PCA is like an expert chef who can quickly assess which ingredients will contribute the most to a dish's overall flavor. This chef combines different ingredients to create a set of new, simplified super-ingredients (principal components). Each of these super-ingredients is a combination of various original ingredients, designed to maximize the flavor (data variance) they bring to the dish.\n",
    "\n",
    "For example, if garlic, onion, and herbs individually add to the dish's flavor, PCA might combine these into a single super-ingredient like a 'flavor base'. This way, instead of dealing with a large number of ingredients, you work with a few super-ingredients that capture the most important flavors of your dish, making the cooking process more efficient and the dish more focused and flavorful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06a403-4dcf-491b-b2ec-cfa98cc684fc",
   "metadata": {},
   "source": [
    "## 2. History of Principal Component Analysis (PCA)\n",
    "\n",
    "1. **Development and History**: Principal Component Analysis (PCA) is a statistical procedure that was invented in 1901 by Karl Pearson as a part of his work on multivariate statistics. It was further developed and named by Harold Hotelling in the 1930s. PCA is used to reduce the dimensionality of large datasets, increasing interpretability while minimizing information loss. It does this by transforming a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.\n",
    "\n",
    "2. **Name Origin**: The name \"Principal Component Analysis\" is derived from the method's goal of identifying the principal components of data variance. In PCA, 'principal' refers to the most important aspects or features of the data that capture the most variance or information in the dataset. The 'components' are the orthogonal axes (in feature space) along which the data is projected to achieve this variance. Thus, PCA essentially analyzes and highlights the main structures or components in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7ca49-7e66-46f2-8737-15f429d2ba1f",
   "metadata": {},
   "source": [
    "## 4. Usecases in Finance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6411337-50b1-400e-82cb-7aa1c7d6a296",
   "metadata": {},
   "source": [
    "- **Dimensionality Reduction in Risk Modeling:** Reducing the number of correlated risk factors in portfolio or credit risk analysis while retaining the most informative components.\n",
    "\n",
    "- **Portfolio Optimization:** Identifying uncorrelated principal components from asset returns to create diversified and efficient portfolios.\n",
    "\n",
    "- **Stock Market Analysis:** Extracting key factors driving stock price movements from large sets of correlated market variables.\n",
    "\n",
    "- **Credit Scoring:** Reducing the dimensionality of borrower attributes to simplify and improve credit risk prediction models.\n",
    "\n",
    "- **Fraud Detection:** Identifying patterns of fraudulent transactions by projecting high-dimensional transaction data into a lower-dimensional space.\n",
    "\n",
    "- **Macroeconomic Indicator Analysis:** Simplifying economic datasets with numerous variables (e.g., GDP, inflation, employment) into principal components to identify major trends.\n",
    "\n",
    "- **Stress Testing:** Combining highly correlated financial variables into principal components for assessing portfolio or institutional performance under stress scenarios.\n",
    "\n",
    "- **Customer Segmentation:** Reducing the dimensionality of financial behavior data to identify meaningful customer clusters for targeted marketing.\n",
    "\n",
    "- **Volatility Analysis:** Simplifying datasets of market volatility factors to better understand and predict fluctuations.\n",
    "\n",
    "- **Time Series Forecasting:** Preprocessing financial time series data by removing noise and extracting key trends for forecasting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf32165-cbd2-4811-9242-8a228a1933e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
